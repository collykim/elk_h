input {
 file{
  path => "/usr/share/logstash/data/test/result/*.csv"
  start_position => "beginning"
  sincedb_path => "/dev/null"
 }
}

filter {
  csv{
    separator => ","
    columns => ["agentId","newRecord","sTotalTime","status","loginStatus","workerInfo","datetime"]
  }
  mutate {
        convert => {"agentId" => "string"}
        convert => {"newRecord" => "integer"}
        convert => {"sTotalTime" => "string"}
        convert => {"status" => "string"}
        convert => {"loginStatus" => "string"}
        convert => {"workerInfo" => "string"}
	convert => {"datetime" => "string"}
  }
}


## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => ["http://elasticsearch:9200"]
		index => "tornado_log"
		user => "elastic"
		password => "changeme"
	}
  stdout {codec => json_lines }
}
